ğŸ“˜ WIKIPEDIA WEB SCRAPER (PYTHON)

A Python-based project that scrapes content from Wikipedia pages ğŸ•¸ï¸ğŸ“„ and saves the extracted information into text files. This project is ideal for beginners who want hands-on experience with web scraping using Python.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ¨ FEATURES
â€¢ ğŸŒ Scrapes data directly from Wikipedia pages
â€¢ ğŸ“¥ Fetches webpage content using HTTP requests
â€¢ ğŸ” Parses HTML with BeautifulSoup
â€¢ ğŸ’¾ Stores extracted content in .txt files
â€¢ ğŸ§© Simple, clean, and easy to understand

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ› ï¸ TECHNOLOGIES USED
â€¢ ğŸ Python
â€¢ ğŸ“¡ Requests
â€¢ ğŸ¥£ BeautifulSoup (bs4)
â€¢ ğŸ““ Jupyter Notebook

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‚ PROJECT STRUCTURE

ğŸ““ wikkipediascraper.ipynb
â†’ Main notebook containing the scraping logic

ğŸ“„ Anime.txt
â†’ Scraped Wikipedia content about Anime

ğŸ“„ Mahatma Gandhi.txt
â†’ Scraped Wikipedia content about Mahatma Gandhi

ğŸ“˜ README.txt
â†’ Project documentation

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ HOW TO RUN THE PROJECT

â‘  Clone the repository
ğŸ”— https://github.com/Kirisaki00/WikipediaScraper.git

â‘¡ Move into the project directory
ğŸ“ WikipediaScraper

â‘¢ Install required libraries
âš™ï¸ requests, beautifulsoup4

â‘£ Open the notebook
â–¶ï¸ Run wikkipediascraper.ipynb in Jupyter

â‘¤ Execute the cells
âœ¨ Text files will be generated automatically

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¤ OUTPUT
âœ”ï¸ Anime.txt â†’ Wikipedia data about Anime ğŸ¬
âœ”ï¸ Mahatma Gandhi.txt â†’ Wikipedia data about Mahatma Gandhi ğŸ‡®ğŸ‡³

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ LEARNING OUTCOMES
â€¢ ğŸ§  Understand web scraping fundamentals
â€¢ ğŸ—ï¸ Learn HTML parsing
â€¢ ğŸ“Š Work with real-world web data
â€¢ ğŸš€ Strengthen Python skills

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ DISCLAIMER
ğŸš« This project is for educational purposes only.
ğŸ“œ Always respect Wikipediaâ€™s terms of service and scraping policies.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸŒ± FUTURE IMPROVEMENTS
â€¢ ğŸ” Scrape multiple pages dynamically
â€¢ ğŸ§¹ Improve text cleaning
â€¢ ğŸ›¡ï¸ Add error handling and logging

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
